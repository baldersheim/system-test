{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Vespa.ai. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Elasticsearch docker container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run -p 9200:9200 -d --name elasticsearch --rm \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"xpack.security.enabled=false\" \\\n",
    "  -e \"xpack.security.http.ssl.enabled=false\" \\\n",
    "  -e \"xpack.license.self_generated.type=trial\" \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:8.13.2\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that docker/podman engine is running\n",
    "\n",
    "Recommended resource configuration:\n",
    "\n",
    "- 8 CPUs\n",
    "- 24 GB RAM\n",
    "- 100+ GB disk space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "\n",
    "client = docker.from_env()\n",
    "docker_network = \"my_network\"\n",
    "\n",
    "# Create a network if it does not exist\n",
    "try:\n",
    "    client.networks.get(docker_network)\n",
    "    print(f\"Network {docker_network} already exists\")\n",
    "except docker.errors.NotFound:\n",
    "    client.networks.create(docker_network, driver=\"bridge\")\n",
    "    print(f\"Network {docker_network} created\")\n",
    "\n",
    "container = client.containers.run(\n",
    "    \"docker.elastic.co/elasticsearch/elasticsearch:8.13.2\",\n",
    "    detach=True,\n",
    "    ports={\"9200/tcp\": 9200},\n",
    "    network=docker_network,\n",
    "    name=\"elasticsearch\",\n",
    "    environment=[\n",
    "        \"discovery.type=single-node\",\n",
    "        \"xpack.security.enabled=false\",\n",
    "        \"xpack.security.http.ssl.enabled=false\",\n",
    "        \"xpack.license.self_generated.type=trial\",\n",
    "    ],\n",
    ")\n",
    "# Wait until container is ready\n",
    "container.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "import time\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "timeout = 30\n",
    "while not es.ping():\n",
    "    timeout -= 1\n",
    "    if timeout == 0:\n",
    "        raise TimeoutError(\"Elasticsearch is not ready\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"product\"\n",
    "\n",
    "# Delete the index if it exists\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\"number_of_shards\": 1, \"number_of_replicas\": 1},\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"integer\"},\n",
    "            \"title\": {\"type\": \"text\", \"similarity\": \"BM25\"},\n",
    "            \"description\": {\"type\": \"text\", \"similarity\": \"BM25\"},\n",
    "            \"category\": {\"type\": \"keyword\"},\n",
    "            \"price\": {\"type\": \"integer\"},\n",
    "            \"average_rating\": {\"type\": \"float\"},\n",
    "            \"embedding\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\",\n",
    "                # See https://www.elastic.co/guide/en/elasticsearch/reference/current/dense-vector.html\n",
    "                \"index_options\": {\"type\": \"hnsw\", \"ef_construction\": 200, \"m\": 16},\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Create the index\n",
    "es.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty-print the mapping\n",
    "mapping = es.indices.get_mapping(index=index_name)\n",
    "mapping.raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed the data to the Elasticsearch container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh feed_to_es.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.indices.refresh(index=index_name)\n",
    "refresh_result = es.cat.count(index=index_name, params={\"format\": \"json\"})\n",
    "refresh_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert refresh_result[0][\"count\"] == \"1000000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For single file (<100MB):\n",
    "\n",
    "```bash\n",
    "curl -s -H \"Content-Type: application/x-ndjson\" -XPOST localhost:9200/_bulk --data-binary \"@../dataprep/output-data/final/es_feed-10k.json\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running fbench against ES-container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompressing query-files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for f in ../dataprep/output-data/final/es_queries-*-10k.json.zst; do zstd -d -f \"$f\" -o \"${f%.zst}\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker command to run fbench against ES-container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker run -v /Users/thomas/Repos/system-test/tests/performance/ecommerce_hybrid_search/dataprep/output-data/final:/files -w /files \\\n",
    "--network my_network \\\n",
    "--entrypoint /opt/vespa/bin/vespa-fbench \\\n",
    "vespaengine/vespa \\\n",
    " -c 0 -s 5 -n 1 -q es_queries-weak_and-10k.json -P -o fbench_output_es_weak_and.txt -D elasticsearch 9200\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the options and base filenames\n",
    "options = [\"weak_and\", \"semantic\", \"hybrid\"]\n",
    "base_query_file = \"es_queries-{}-10k.json\"\n",
    "base_output_file = \"fbench_output_{}.txt\"\n",
    "result_file = \"fbench_results_{}.txt\"\n",
    "# Generate the configurations dynamically\n",
    "configs = [\n",
    "    {\n",
    "        \"option\": option,\n",
    "        \"query_file\": base_query_file.format(option),\n",
    "        \"output_file\": base_output_file.format(option),\n",
    "        \"result_file\": result_file.format(option),\n",
    "    }\n",
    "    for option in options\n",
    "]\n",
    "\n",
    "# Loop through each configuration and run the container\n",
    "for config in configs:\n",
    "    print(f\"Running fbench in container for {config['option']} queries\")\n",
    "    output = client.containers.run(\n",
    "        image=\"vespaengine/vespa\",\n",
    "        entrypoint=\"/opt/vespa/bin/vespa-fbench\",  # Set vespa-fbench as the entrypoint\n",
    "        network=docker_network,\n",
    "        command=[\n",
    "            \"-c\",\n",
    "            \"0\",\n",
    "            \"-s\",\n",
    "            \"30\",\n",
    "            \"-n\",\n",
    "            \"1\",\n",
    "            \"-q\",\n",
    "            config[\"query_file\"],\n",
    "            \"-P\",\n",
    "            \"-o\",\n",
    "            config[\"output_file\"],\n",
    "            \"-D\",\n",
    "            \"elasticsearch\",\n",
    "            \"9200\",\n",
    "        ],\n",
    "        volumes={\n",
    "            \"/Users/thomas/Repos/system-test/tests/performance/ecommerce_hybrid_search/dataprep/output-data/final\": {\n",
    "                \"bind\": \"/files\",\n",
    "                \"mode\": \"rw\",\n",
    "            }\n",
    "        },\n",
    "        working_dir=\"/files\",\n",
    "        detach=False,\n",
    "        remove=True,\n",
    "    )\n",
    "\n",
    "    # Wait for the container to finish and print the output\n",
    "    result = output.decode(\"utf-8\")\n",
    "    print(f\"Output for {config['option']} queries:\\n{result}\")\n",
    "    # Save results to a file\n",
    "    with open(config[\"result_file\"], \"w\") as file:\n",
    "        file.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the ES container\n",
    "container.stop()\n",
    "container.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  # Just to stop the execution here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
